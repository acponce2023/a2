{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acponce2023/a2/blob/main/filtering_process_V3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_r_GRpyEMlXJ"
      },
      "source": [
        "En este cuaderno se encuentra una adaptación del proceso de filtrado para que podáis trabajar con él y ver su funcionamiento más en detalle.\n",
        "\n",
        "Hay algunos ficheros que tendréis que poner en las carpetas que corresponda, por ejemplo todos los ficheros de frecuencias.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lmqkM0gzJcS"
      },
      "outputs": [],
      "source": [
        "!pip install spacy lingua-language-detector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Xrh50SbGzzzF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00fa482b-354c-4e79-d0aa-44e0891ec0cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "freq/fre/\n",
            "freq/fre/fre-1gram.txt\n",
            "freq/spa/spa-1gram.txt\n",
            "freq/ger/\n",
            "freq/spa/\n",
            "freq/ita/ita-2gram.txt\n",
            "freq/ita/ita-1gram.txt\n",
            "freq/ger/ger-2gram.txt\n",
            "freq/ger/ger-1gram.txt\n",
            "freq/eng/\n",
            "freq/\n",
            "freq/eng/eng-2gram.txt\n",
            "freq/ita/\n",
            "freq/eng/eng-1gram.txt\n",
            "freq/fre/fre-2gram.txt\n",
            "freq/spa/spa-2gram.txt\n",
            "extract/eng/occupational_therapy/\n",
            "extract/spa/occupational_therapy/\n",
            "extract/fre/occupational_therapy/\n",
            "extract/spa/\n",
            "extract/spa/occupational_therapy/terms.txt\n",
            "extract/fre/occupational_therapy/terms.txt\n",
            "extract/ger/occupational_therapy/terms.txt\n",
            "extract/eng/\n",
            "extract/ger/occupational_therapy/\n",
            "extract/ita/\n",
            "extract/eng/occupational_therapy/terms.txt\n",
            "extract/ita/occupational_therapy/terms.txt\n",
            "extract/fre/\n",
            "extract/ita/occupational_therapy/\n",
            "extract/ger/\n",
            "extract/\n"
          ]
        }
      ],
      "source": [
        "!tar -xvf freq.tar\n",
        "!tar -xvf extract.tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQnMIGfd0dka"
      },
      "outputs": [],
      "source": [
        "!spacy download en_core_web_sm\n",
        "!spacy download de_core_news_sm\n",
        "!spacy download fr_core_news_sm\n",
        "!spacy download it_core_news_sm\n",
        "!spacy download es_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ZQpRAnvHB5cO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d2158e7-962b-496a-aa33-d4d3036a4ef9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num. palabras unicas en spa:  50001\n",
            "Num. 2 palabras asociadas en spa:  100001\n",
            "Num. palabras unicas en eng:  3136241\n",
            "Num. 2 palabras asociadas en eng:  5866953\n",
            "Num. palabras unicas en ger:  50001\n",
            "Num. 2 palabras asociadas en ger:  100001\n",
            "Num. palabras unicas en fre:  50001\n",
            "Num. 2 palabras asociadas en fre:  100001\n",
            "Num. palabras unicas en ita:  748540\n",
            "Num. 2 palabras asociadas en ita:  77739\n",
            "[Language.ENGLISH, Language.SPANISH, Language.ITALIAN, Language.GERMAN, Language.FRENCH]\n",
            "<builtins.LanguageDetector object at 0x79f5726b2b10>\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import traceback\n",
        "import uuid\n",
        "import os\n",
        "import spacy\n",
        "import json\n",
        "\n",
        "import lingua\n",
        "\n",
        "# Spacy\n",
        "\n",
        "spacy_models = json.loads('''{\n",
        "\t\"bul\": {\"sm\": null, \"lg\": null},\n",
        "\t\"hrv\": {\"sm\": \"hr_core_news_sm\", \"lg\": \"hr_core_news_lg\"},\n",
        "\t\"cze\": {\"sm\": null, \"lg\": null},\n",
        "\t\"dan\": {\"sm\": \"da_core_news_sm\", \"lg\": \"da_core_news_trf\"},\n",
        "\t\"dut\": {\"sm\": \"nl_core_news_sm\", \"lg\": \"nl_core_news_lg\"},\n",
        "\t\"eng\": {\"sm\": \"en_core_web_sm\", \"lg\": \"en_core_web_trf\"},\n",
        "\t\"est\": {\"sm\": null, \"lg\": null},\n",
        "\t\"fin\": {\"sm\": \"fi_core_news_sm\", \"lg\": \"fi_core_news_lg\"},\n",
        "\t\"fre\": {\"sm\": \"fr_core_news_sm\", \"lg\": \"fr_dep_news_trf\"},\n",
        "\t\"ger\": {\"sm\": \"de_core_news_sm\", \"lg\": \"de_dep_news_trf\"},\n",
        "\t\"gre\": {\"sm\": \"el_core_news_sm\", \"lg\": \"el_core_news_lg\"},\n",
        "\t\"hun\": {\"sm\": null, \"lg\": null},\n",
        "\t\"gle\": {\"sm\": null, \"lg\": null},\n",
        "\t\"ita\": {\"sm\": \"it_core_news_sm\", \"lg\": \"it_core_news_lg\"},\n",
        "\t\"lav\": {\"sm\": null, \"lg\": null},\n",
        "\t\"lit\": {\"sm\": \"lt_core_news_sm\", \"lg\": \"lt_core_news_lg\"},\n",
        "\t\"mlt\": {\"sm\": null, \"lg\": null},\n",
        "\t\"pol\": {\"sm\": \"pl_core_news_sm\", \"lg\": \"pl_core_news_lg\"},\n",
        "\t\"por\": {\"sm\": \"pt_core_news_sm\", \"lg\": \"pt_core_news_lg\"},\n",
        "\t\"rum\": {\"sm\": \"ro_core_news_sm\", \"lg\": \"ro_core_news_lg\"},\n",
        "\t\"rus\": {\"sm\": \"ru_core_news_sm\", \"lg\": \"ru_core_news_lg\"},\n",
        "\t\"slo\": {\"sm\": null, \"lg\": null},\n",
        "\t\"slv\": {\"sm\": null, \"lg\": null},\n",
        "\t\"spa\": {\"sm\": \"es_core_news_sm\", \"lg\": \"es_dep_news_trf\"},\n",
        "\t\"swe\": {\"sm\": null, \"lg\": null}\n",
        "}''')\n",
        "\n",
        "\n",
        "freq_list = {\"spa\": {}, \"ger\": {}, \"fre\": {}, \"eng\": {}, \"ita\": {}}\n",
        "\n",
        "freq_list[\"spa\"][\"1-gram\"] = open(\"./freq/spa/spa-1gram.txt\").read().split(\"\\n\")\n",
        "freq_list[\"ger\"][\"1-gram\"] = open(\"./freq/ger/ger-1gram.txt\").read().split(\"\\n\")\n",
        "freq_list[\"fre\"][\"1-gram\"] = open(\"./freq/fre/fre-1gram.txt\").read().split(\"\\n\")\n",
        "freq_list[\"eng\"][\"1-gram\"] = open(\"./freq/eng/eng-1gram.txt\").read().split(\"\\n\")\n",
        "freq_list[\"ita\"][\"1-gram\"] = open(\"./freq/ita/ita-1gram.txt\").read().split(\"\\n\")\n",
        "\n",
        "freq_list[\"spa\"][\"2-gram\"] = open(\"./freq/spa/spa-2gram.txt\").read().split(\"\\n\")\n",
        "freq_list[\"ger\"][\"2-gram\"] = open(\"./freq/ger/ger-2gram.txt\").read().split(\"\\n\")\n",
        "freq_list[\"fre\"][\"2-gram\"] = open(\"./freq/fre/fre-2gram.txt\").read().split(\"\\n\")\n",
        "freq_list[\"eng\"][\"2-gram\"] = open(\"./freq/eng/eng-2gram.txt\").read().split(\"\\n\")\n",
        "freq_list[\"ita\"][\"2-gram\"] = open(\"./freq/ita/ita-2gram.txt\").read().split(\"\\n\")\n",
        "## --->\n",
        "print(\"Num. palabras unicas en spa: \",len(freq_list[\"spa\"][\"1-gram\"]))\n",
        "print(\"Num. 2 palabras asociadas en spa: \", len(freq_list[\"spa\"][\"2-gram\"]))\n",
        "#print(freq_list[\"spa\"][\"1-gram\"])\n",
        "#print(freq_list[\"spa\"][\"2-gram\"])\n",
        "print(\"Num. palabras unicas en eng: \", len(freq_list[\"eng\"][\"1-gram\"]))\n",
        "print(\"Num. 2 palabras asociadas en eng: \", len(freq_list[\"eng\"][\"2-gram\"]))\n",
        "#print(freq_list[\"eng\"][\"1-gram\"])\n",
        "#print(freq_list[\"eng\"][\"2-gram\"])\n",
        "print(\"Num. palabras unicas en ger: \", len(freq_list[\"ger\"][\"1-gram\"]))\n",
        "print(\"Num. 2 palabras asociadas en ger: \", len(freq_list[\"ger\"][\"2-gram\"]))\n",
        "#print(freq_list[\"ger\"][\"1-gram\"])\n",
        "#print(freq_list[\"ger\"][\"2-gram\"])\n",
        "print(\"Num. palabras unicas en fre: \", len(freq_list[\"fre\"][\"1-gram\"]))\n",
        "print(\"Num. 2 palabras asociadas en fre: \", len(freq_list[\"fre\"][\"2-gram\"]))\n",
        "#print(freq_list[\"fre\"][\"1-gram\"])\n",
        "#print(freq_list[\"fre\"][\"2-gram\"])\n",
        "print(\"Num. palabras unicas en ita: \", len(freq_list[\"ita\"][\"1-gram\"]))\n",
        "print(\"Num. 2 palabras asociadas en ita: \", len(freq_list[\"ita\"][\"2-gram\"]))\n",
        "#print(freq_list[\"ita\"][\"1-gram\"])\n",
        "#print(freq_list[\"ita\"][\"2-gram\"])\n",
        "## --->\n",
        "lingua_langs = {\n",
        "\t\t\"eng\": lingua.Language.ENGLISH,\n",
        "\t\t\"spa\": lingua.Language.SPANISH,\n",
        "\t\t\"ita\": lingua.Language.ITALIAN,\n",
        "\t\t\"ger\": lingua.Language.GERMAN,\n",
        "\t\t\"fre\": lingua.Language.FRENCH\n",
        "\t}\n",
        "\n",
        "langs_used = [v for k,v in lingua_langs.items()]\n",
        "## --->\n",
        "print(langs_used)\n",
        "## --->\n",
        "lang_detector = lingua.LanguageDetectorBuilder.from_languages(*langs_used).build()\n",
        "## --->\n",
        "print (lang_detector)\n",
        "## --->"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example = open(\"./extract/spa/occupational_therapy/terms.txt\").readlines()\n",
        "## -->\n",
        "print(\"Total de terminos a filtrar spa: \", len(example))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJahkNKdKS6_",
        "outputId": "b2bfe6ca-9dad-4bb1-eec8-2ab8b532dd6d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de terminos a filtrar spa:  7581\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## -->\n",
        "terms = filter_terms(example, \"spa\")\n",
        "## -->\n"
      ],
      "metadata": {
        "id": "z3ueXR9PNuvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## -->\n",
        "print(\"Total terminos filtrados spa: \", len(terms))\n",
        "#print(\"Terminos filtrados\", terms)\n",
        "## -->"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJ7PlJr0OQ_I",
        "outputId": "e7ef418b-46a7-4d27-e1d3-a791113829d2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total terminos filtrados spa:  1225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "terms = lemmatize_terms(terms, \"spa\")\n",
        "## -->\n",
        "print(\"Total terminos lematizados spa: \", len(terms))\n",
        "#print(\"Terminos lematizados: \", terms)\n",
        "## -->\n",
        "# Matriz Confusion\n",
        "# Definimos el listado inicial como A y el listado final como B, los valores de la matriz los podemos razonar de la siguiente forma:\n",
        "# A :terminos a filtrar  SPA ; B: Términos filtrados y lematizados\n",
        "#TP: la intersección de A y B\n",
        "#FP: los valores de A no contenidos en B\n",
        "#FN: los valores de B no contenidos en A\n",
        "#TN: ¿?\n",
        "\n",
        "# TP      FN\n",
        "# FP      TN\n",
        "#----------->\n",
        "# 1.197   0\n",
        "# 6.654   0\n",
        "\n",
        "print(\"PRECISION = TP /(TP + FP) =\" , 1197 / 7581)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_7xqI0gOjDB",
        "outputId": "19730e0d-4f06-4333-d166-aa0979b2e5e9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total terminos lematizados spa:  1197\n",
            "PRECISION = TP /(TP + FP) = 0.15789473684210525\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example = open(\"./extract/ger/occupational_therapy/terms.txt\").readlines()\n",
        "## -->\n",
        "print(\"Total de terminos a fltrar ger: \", len(example))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeAR2VsHP5ga",
        "outputId": "c2305082-cd29-42bf-c13b-50c33d5c00db"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de terminos a fltrar ger:  4001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## -->\n",
        "terms = filter_terms(example, \"ger\")\n",
        "## -->"
      ],
      "metadata": {
        "id": "hjh-Sg0PP59g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total terminos filtrados ger\", len(terms))\n",
        "#print(\"Terminos filtrados\", terms)\n",
        "## -->"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QccEws3P6ZP",
        "outputId": "9f09d6f2-d598-4282-9186-c5aa10af9e4f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total terminos filtrados ger 1210\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "terms = lemmatize_terms(terms, \"ger\")\n",
        "## -->\n",
        "print(\"Total terminos lematizados ger: \", len(terms))\n",
        "#print(\"Terminos lematizados: \", terms)\n",
        "## -->\n",
        "# Matriz Confusion\n",
        "# Definimos el listado inicial como A y el listado final como B, los valores de la matriz los podemos razonar de la siguiente forma:\n",
        "# A :terminos a filtrar  GER ; B: Términos filtrados y lematizados\n",
        "#TP: la intersección de A y B\n",
        "#FP: los valores de A no contenidos en B\n",
        "#FN: los valores de B no contenidos en A\n",
        "#TN: ¿?\n",
        "\n",
        "# TP      FN\n",
        "# FP      TN\n",
        "#----------->\n",
        "# 1.157   0\n",
        "# 2.844   0\n",
        "\n",
        "print(\"PRECISION = TP /(TP + FP) =\" , 1157 / 4001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPnjGByeP6zf",
        "outputId": "a5f0acff-78f6-4fcc-ab2f-27765000455c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total terminos lematizados ger:  1157\n",
            "PRECISION = TP /(TP + FP) = 0.2891777055736066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example = open(\"./extract/fre/occupational_therapy/terms.txt\").readlines()\n",
        "## -->\n",
        "print(\"Total de terminos a filtrar fre: \", len(example))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZ23nncPQaCL",
        "outputId": "12238a6d-0549-465e-ebe6-f5ca682501f3"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de terminos a filtrar fre:  5742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "terms = filter_terms(example, \"fre\")"
      ],
      "metadata": {
        "id": "AlFwY_LzQaY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## -->\n",
        "print(\"Total terminos filtrados fre\", len(terms))\n",
        "#print(\"Terminos filtrados\", terms)\n",
        "## -->"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQzRr2rfQauw",
        "outputId": "5ed1fe50-07d7-45d8-d2d0-700869d40de4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total terminos filtrados fre 1015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## -->\n",
        "terms = lemmatize_terms(terms, \"fre\")\n",
        "## -->\n",
        "print(\"Total terminos lematizados fre: \", len(terms))\n",
        "#print(\"Terminos lematizados: \", terms)\n",
        "## -->\n",
        "# Matriz Confusion\n",
        "# Definimos el listado inicial como A y el listado final como B, los valores de la matriz los podemos razonar de la siguiente forma:\n",
        "# A :terminos a filtrar  FRE ; B: Términos filtrados y lematizados\n",
        "#TP: la intersección de A y B\n",
        "#FP: los valores de A no contenidos en B\n",
        "#FN: los valores de B no contenidos en A\n",
        "#TN: ¿?\n",
        "\n",
        "# TP      FN\n",
        "# FP      TN\n",
        "#----------->\n",
        "#   981    0\n",
        "# 4.761    0\n",
        "\n",
        "print(\"PRECISION = TP /(TP + FP) =\" , 981 / 5742)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wFUYS8NQbEJ",
        "outputId": "99fb5a6e-a74c-4030-eab1-e7640699eea2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total terminos lematizados fre:  981\n",
            "PRECISION = TP /(TP + FP) = 0.17084639498432602\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example = open(\"./extract/eng/occupational_therapy/terms.txt\").readlines()\n",
        "## -->\n",
        "print(\"Total de terminos a filtrar eng: \", len(example))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUXkN0GOROFc",
        "outputId": "3fa5057a-792e-404f-a1c7-a796ca470580"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de terminos a filtrar eng:  4902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "terms = filter_terms(example, \"eng\")"
      ],
      "metadata": {
        "id": "yTtHjuZmROax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## -->\n",
        "print(\"Total terminos filtrados eng\", len(terms))\n",
        "#print(\"Terminos filtrados\", terms)\n",
        "## -->"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVP5rNgrROwJ",
        "outputId": "a49b5378-1e04-475a-a49c-bf7bf306bb55"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total terminos filtrados eng 1263\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## -->\n",
        "terms = lemmatize_terms(terms, \"eng\")\n",
        "## -->\n",
        "print(\"Total terminos lematizados eng: \", len(terms))\n",
        "#print(\"Terminos lematizados: \", terms)\n",
        "## -->\n",
        "# Matriz Confusion\n",
        "# Definimos el listado inicial como A y el listado final como B, los valores de la matriz los podemos razonar de la siguiente forma:\n",
        "# A :terminos a filtrar  ENG ; B: Términos filtrados y lematizados\n",
        "#TP: la intersección de A y B\n",
        "#FP: los valores de A no contenidos en B\n",
        "#FN: los valores de B no contenidos en A\n",
        "#TN: ¿?\n",
        "\n",
        "# TP      FN\n",
        "# FP      TN\n",
        "#----------->\n",
        "# 1159   0\n",
        "# 4116   0\n",
        "\n",
        "print(\"PRECISION = TP /(TP + FP) =\" , 1159/ 4902)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_vEMlGzRPDR",
        "outputId": "07cf2776-860e-46b0-ef2f-65883c80e1c3"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total terminos lematizados eng:  1159\n",
            "PRECISION = TP /(TP + FP) = 0.2364341085271318\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example = open(\"./extract/ita/occupational_therapy/terms.txt\").readlines()\n",
        "## -->\n",
        "print(\"Total de terminos a filtrar ita: \", len(example))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Esx4_pYo0YYr",
        "outputId": "2343e335-ebe7-4db8-e716-fa74059f4a05"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de terminos a filtrar ita:  2709\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "terms = filter_terms(example, \"ita\")"
      ],
      "metadata": {
        "id": "S7DYbG0K0eK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## -->\n",
        "print(\"Total terminos filtrados ita\", len(terms))\n",
        "#print(\"Terminos filtrados\", terms)\n",
        "## -->"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRnFN9JQ0mJY",
        "outputId": "29abbaf3-3029-412a-a04f-c96c0166113d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total terminos filtrados ita 393\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## -->\n",
        "terms = lemmatize_terms(terms, \"ita\")\n",
        "## -->\n",
        "print(\"Total terminos lematizados ita: \", len(terms))\n",
        "#print(\"Terminos lematizados: \", terms)\n",
        "## -->\n",
        "# Matriz Confusion\n",
        "# Definimos el listado inicial como A y el listado final como B, los valores de la matriz los podemos razonar de la siguiente forma:\n",
        "# A :terminos a filtrar  ITA ; B: Términos filtrados y lematizados\n",
        "#TP: la intersección de A y B\n",
        "#FP: los valores de A no contenidos en B\n",
        "#FN: los valores de B no contenidos en A\n",
        "#TN: ¿?\n",
        "\n",
        "# TP      FN\n",
        "# FP      TN\n",
        "#----------->\n",
        "# 388   0\n",
        "# 2.321   0\n",
        "\n",
        "print(\"PRECISION = TP /(TP + FP) =\" , 388/ 2709)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0iWAdp20vxm",
        "outputId": "6beb3f20-4203-4543-827d-fe3a625b50a9"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total terminos lematizados ita:  387\n",
            "PRECISION = TP /(TP + FP) = 0.14322628276116647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "NiEWgGzSMXAf"
      },
      "outputs": [],
      "source": [
        "def filter_terms(lines, lang):\n",
        "\n",
        "\tterms = {}\n",
        "\tfilter_deep_1g = 50001\n",
        "\tfilter_deep_2g = 1000000\n",
        "\t#filter_deep_1g = 3200000\n",
        "\t#filter_deep_2g = 6000000\n",
        "\n",
        "\tdict_1g = {}\n",
        "\tdict_2g = {}\n",
        "\n",
        "\n",
        "\tif (lang in freq_list) and (\"1-gram\" in freq_list[lang]):\n",
        "\n",
        "\t\tlower_list = [t.lower() for t in freq_list[lang][\"1-gram\"][:filter_deep_1g]]\n",
        "\n",
        "\t\tdict_1g = dict(zip(lower_list, range(len(lower_list))))\n",
        "## --->\n",
        "#\tprint (dict_1g)\n",
        "## --->\n",
        "\tif (lang in freq_list) and (\"2-gram\" in freq_list[lang]):\n",
        "\n",
        "\t\tlower_list = [t.lower() for t in freq_list[lang][\"2-gram\"][:filter_deep_2g]]\n",
        "\n",
        "\t\tdict_2g = dict(zip(lower_list, range(len(lower_list))))\n",
        "## --->\n",
        "#\tprint(dict_2g)\n",
        "## --->\n",
        "\n",
        "\tfor term in lines:\n",
        "\n",
        "\t\tfreq, term = term.replace(\"\\n\", \"\").split(\"\\t\")\n",
        "\n",
        "\t\tterm = term.replace(\"-\", \" \").replace(\"  \", \" \")\n",
        "\n",
        "\t\tif (lang in freq_list) and (\"1-gram\" in freq_list[lang]) and (term.lower() in dict_1g):\n",
        "\n",
        "\t\t\tprint(\"Excluding\", term, \"(too freq 1-gram)\")\n",
        "\n",
        "\n",
        "\t\telif (lang in freq_list) and (\"2-gram\" in freq_list[lang]) and (term.lower() in dict_2g):\n",
        "\n",
        "\t\t\tprint(\"Excluding\", term, \"(too freq 2-gram)\")\n",
        "\n",
        "\n",
        "\t\telif any(len(word) < 4 for word in term.split(\" \")):\n",
        "\n",
        "\t\t\tprint(\"Excluding\", term, \"(too short)\")\n",
        "\n",
        "\n",
        "\t\telif not term.replace(\" \", \"\").replace(\"'\", \"\").replace(\"-\",\"\").isalpha() or term.replace(\" \", \"\").startswith(\"-\") or term.replace(\" \", \"\").endswith(\"-\"):\n",
        "\n",
        "\t\t\tprint(\"Excluding\", term, \"(strange symbols)\")\n",
        "\n",
        "\t\telse:\n",
        "\n",
        "\t\t\tprint(\"Adding\", term)\n",
        "\n",
        "\t\t\tterms[term] = {\"f\": freq}\n",
        "\n",
        "\n",
        "\t# Las diferencias de capitalizacion se resuelven optando por la version mas habitual\n",
        "\n",
        "\tfor term, obj in terms.copy().items():\n",
        "\n",
        "\t\tif term.lower() != term and term.lower() in terms:\n",
        "\n",
        "\t\t\tif int(terms[term.lower()][\"f\"]) > int(terms[term][\"f\"]):\n",
        "\n",
        "\t\t\t\tterms.pop(term)\n",
        "\n",
        "\t\t\t\tprint(\"Excluding\", term, \"(duplicated and less frequent capitalization)\")\n",
        "\n",
        "\t\t\telse:\n",
        "\n",
        "\t\t\t\tterms.pop(term.lower())\n",
        "\n",
        "\t\tprint(\"Excluding\", term.lower(), \"(duplicated and less frequent capitalization)\")\n",
        "\n",
        "\n",
        "\tvalid_NE = [\"EVENT\", \"FAC\", \"ORG\", \"WORK_OF_ART\"]\n",
        "\n",
        "\tpipe = spacy.load(spacy_models[lang][\"sm\"])\n",
        "\n",
        "\tfor term, obj in terms.copy().items():\n",
        "\n",
        "\t\tdoc = pipe(term)\n",
        "\n",
        "\t\tfor token in doc.ents:\n",
        "\n",
        "\t\t\tprint(\"Found NE: \", token.text, token.label_)\n",
        "\n",
        "\t\t\tif not (token.label_ in valid_NE) and term in terms:\n",
        "\n",
        "\t\t\t\tterms.pop(term)\n",
        "\n",
        "\n",
        "\tfor term, obj in terms.copy().items():\n",
        "\n",
        "\t\tdetected = lang_detector.detect_language_of(term)\n",
        "\n",
        "\t\tprint(term, detected)\n",
        "\n",
        "\t\tif lang in lingua_langs and detected != lingua_langs[lang]:\n",
        "\n",
        "\t\t\tterms.pop(term)\n",
        "\n",
        "\n",
        "\treturn terms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "5FH0edJrB073"
      },
      "outputs": [],
      "source": [
        "def lemmatize_terms(terms, lang):\n",
        "\n",
        "\tlemmatized_terms = {}\n",
        "\n",
        "\tpipe = spacy.load(spacy_models[lang][\"sm\"])\n",
        "\n",
        "\tterm_list_old = list(terms.keys())\n",
        "\n",
        "\tfor term in term_list_old:\n",
        "\n",
        "\t\tdoc = pipe(term)\n",
        "\n",
        "\t\tfull_token = []\n",
        "\n",
        "\t\tfor token in doc:\n",
        "\n",
        "\t\t\tfull_token.append(token.lemma_)\n",
        "\n",
        "\t\tlemma = \" \".join(full_token)\n",
        "\n",
        "\t\tif term in terms:\n",
        "\n",
        "\t\t\told_f = terms[term]\n",
        "\n",
        "\t\t\tif lemma in lemmatized_terms:\n",
        "\n",
        "\t\t\t\tcurrent_f = lemmatized_terms[lemma]\n",
        "\n",
        "\t\t\t\tnew_f = current_f[\"f\"] + old_f[\"f\"] # Varias palabras convergen en una raíz\n",
        "\n",
        "\t\t\t\tlemmatized_terms[lemma] = {\"f\": new_f}\n",
        "\n",
        "\t\t\telse:\n",
        "\n",
        "\t\t\t\tlemmatized_terms[lemma] = {\"f\": old_f[\"f\"]}\n",
        "\n",
        "\t# Se reaplica filtrado a las palabras luego de filtrarlas, esto estaría\n",
        "  # mejor hacerlo de otra forma, hay código repetido\n",
        "\n",
        "\tfilter_deep_1g = 500001\n",
        "\tfilter_deep_2g = 1000000\n",
        "\t#filter_deep_1g = 3200000\n",
        "\t#filter_deep_2g = 6000000\n",
        "\n",
        "\tdict_1g = {}\n",
        "\tdict_2g = {}\n",
        "\n",
        "\tif (lang in freq_list) and (\"1-gram\" in freq_list[lang]):\n",
        "\n",
        "\t\tlower_list = [t.lower() for t in freq_list[lang][\"1-gram\"][:filter_deep_1g]]\n",
        "\n",
        "\t\tdict_1g = dict(zip(lower_list, range(len(lower_list))))\n",
        "\n",
        "\tif (lang in freq_list) and (\"2-gram\" in freq_list[lang]):\n",
        "\n",
        "\t\tlower_list = [t.lower() for t in freq_list[lang][\"2-gram\"][:filter_deep_2g]]\n",
        "\n",
        "\t\tdict_2g = dict(zip(lower_list, range(len(lower_list))))\n",
        "\n",
        "\n",
        "\tfor term in lemmatized_terms.copy().keys():\n",
        "\n",
        "    # Solo se extá empleando en \"eng\" porque la lematización en otras cambia\n",
        "    # también otras flexiones y es algo a evitar.\n",
        "\n",
        "\t\tif lang == \"eng\":\n",
        "\n",
        "\t\t\tif (term.lower() in dict_1g):\n",
        "\n",
        "#\t\t\t\tprint(\"Excluding\", term, \"(too freq 1-gram) lemma\")\n",
        "\n",
        "\t\t\t\tlemmatized_terms.pop(term)\n",
        "\n",
        "\t\t\telif (term.lower() in dict_2g):\n",
        "\n",
        "\t#\t\t\tprint(\"Excluding\", term, \"(too freq 2-gram) lemma\")\n",
        "\n",
        "\t\t\t\tlemmatized_terms.pop(term)\n",
        "\n",
        "\treturn lemmatized_terms\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}